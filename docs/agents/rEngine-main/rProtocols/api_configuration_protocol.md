# API Configuration Protocol for StackTrackr

**Version:** 1.0  
**Purpose:** Secure, user-friendly API key configuration system  
**Security Level:** Local encryption with user-managed passwords  

## Overview

This protocol provides a secure, streamlined way for users to configure API keys for StackTrackr's LLM integration system. API keys are encrypted locally and never transmitted or stored in plain text.

## Quick Setup Guide

### Step 1: Initial Configuration

```bash

# Navigate to rEngine directory

cd /Volumes/DATA/GitHub/rEngine/rEngine

# Run the configuration wizard

node configure-apis.js
```

### Step 2: Test Your Setup

```bash

# Test all configured providers

node call-llm.js --list

# Test a specific provider

node call-llm.js --provider gemini --prompt "Hello, test message"
```

## Supported LLM Providers

| Provider | Models Available | Use Case |
|----------|------------------|----------|
| **Gemini** | `gemini-1.5-flash`, `gemini-1.5-pro` | Fast analysis, documentation |
| **Claude** | `claude-3-5-sonnet`, `claude-3-haiku` | Code analysis, architecture |
| **OpenAI** | `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo` | General tasks, implementation |
| **Groq** | `mixtral-8x7b`, `llama-3.1-70b`, `llama-3.1-8b` | Fast inference, testing |

## Security Features

### üîê Local Encryption

- API keys encrypted with user-chosen password
- Keys never stored in plain text
- Password never stored - you choose and remember it

### üõ°Ô∏è Environment Isolation

- Separate `.env` file for API keys
- Git-ignored by default
- Local file system permissions protect access

### üîÑ Session Management

- Keys decrypted only when needed
- Automatic session timeout for security
- Easy lock/unlock workflow

## Configuration Methods

### Method 1: Interactive Wizard (Recommended)

```bash
node configure-apis.js
```

## Features:

- Step-by-step guidance
- Built-in validation
- Secure password entry
- Test each provider as you configure

### Method 2: Direct Configuration

```bash

# Set individual API keys

node configure-apis.js --provider gemini --key YOUR_API_KEY
node configure-apis.js --provider claude --key YOUR_API_KEY
```

### Method 3: Bulk Import

```bash

# Import from secure configuration file

node configure-apis.js --import config.json
```

## API Key Sources

### Google Gemini

1. Go to [Google AI Studio](https://aistudio.google.com/)
2. Click "Get API Key"
3. Create new project or use existing
4. Copy API key (starts with `AIza...`)

### Anthropic Claude

1. Visit [Anthropic Console](https://console.anthropic.com/)
2. Go to "API Keys" section
3. Create new key
4. Copy API key (starts with `sk-ant-...`)

### OpenAI

1. Go to [OpenAI Platform](https://platform.openai.com/)
2. Navigate to "API Keys"
3. Create new secret key
4. Copy API key (starts with `sk-proj-...`)

### Groq

1. Visit [Groq Console](https://console.groq.com/)
2. Go to "API Keys"
3. Generate new key
4. Copy API key (starts with `gsk_...`)

## Usage Examples

### Basic LLM Calls

```bash

# Quick analysis with Gemini

node call-llm.js -p gemini --prompt "Analyze this code performance"

# Detailed architecture review with Claude

node call-llm.js -p claude -m claude-3-5-sonnet --prompt "Review system architecture"

# Fast prototyping with Groq

node call-llm.js -p groq --prompt "Generate test cases for this function"
```

### MCP Integration

```bash

# Use in MCP workflows

echo '{"provider":"gemini","prompt":"Document this function"}' | node call-llm.js --mcp
```

### rAgent Integration

```bash

# Available to all rAgents through MCP tools

# rAgents can now call any configured LLM directly

```

## Configuration File Structure

### `.env` (Auto-generated)

```properties

# Generated by configure-apis.js

GEMINI_API_KEY=AIzaSy...
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-proj-...
GROQ_API_KEY=gsk_...
OLLAMA_BASE_URL=http://localhost:11434
```

### `api-config.json` (Encrypted metadata)

```json
{
  "version": "1.0",
  "providers": {
    "gemini": {
      "configured": true,
      "models": ["gemini-1.5-flash", "gemini-1.5-pro"],
      "default_model": "gemini-1.5-flash",
      "last_tested": "2025-08-19T10:30:00Z"
    }
  },
  "security": {
    "encryption_method": "AES-256-GCM",
    "key_derivation": "PBKDF2",
    "last_updated": "2025-08-19T10:30:00Z"
  }
}
```

## Security Best Practices

### ‚úÖ Do's

- Use strong, unique passwords for encryption
- Test configurations immediately after setup
- Keep API keys in your password manager
- Review provider usage limits regularly
- Use appropriate models for each task

### ‚ùå Don'ts

- Share your configuration password
- Commit `.env` files to version control
- Use the same password for multiple systems
- Store API keys in plain text files
- Ignore API usage notifications

## Troubleshooting

### Common Issues

#### "API Key not found"

```bash

# Check if keys are properly configured

node configure-apis.js --status

# Reconfigure if needed

node configure-apis.js --provider gemini
```

#### "Authentication failed"

```bash

# Test API key validity

node call-llm.js --provider gemini --prompt "test" --debug

# Update expired key

node configure-apis.js --provider gemini --update
```

#### "Rate limit exceeded"

```bash

# Check usage status

node configure-apis.js --usage

# Switch to different provider temporarily

node call-llm.js --provider groq --prompt "your request"
```

## Integration Points

### With rEngine MCP Tools

- All MCP tools can now call LLMs directly
- Automatic provider selection based on task type
- Unified error handling and logging

### With rAgents

- rAgents gain instant access to all configured LLMs
- Smart provider routing based on agent capabilities
- Shared conversation context and memory

### With Search Matrix

- LLM calls can be enriched with search matrix context
- Automatic context injection for better responses
- Pattern recognition across LLM interactions

## Performance Optimization

### Provider Selection Guidelines

- **Groq**: Fastest inference, good for quick tasks
- **Gemini**: Best price/performance ratio
- **GPT-4**: Most capable for complex reasoning
- **Claude**: Best for code analysis and architecture

### Cost Management

- Monitor usage through provider dashboards
- Set up billing alerts
- Use faster models for development/testing
- Reserve premium models for production tasks

## Maintenance

### Regular Tasks

- Update API keys before expiration
- Review usage patterns monthly
- Test all providers quarterly
- Update model configurations as new versions release

### Monitoring

```bash

# Check system health

node configure-apis.js --health

# View call history

tail -f ../logs/llm-calls.jsonl

# Usage analytics

node analyze-llm-usage.js --month current
```

---

## Quick Reference Commands

```bash

# Setup

node configure-apis.js                    # Interactive setup
node configure-apis.js --status           # Check configuration

# Usage

node call-llm.js -p gemini --prompt "..."  # Call Gemini
node call-llm.js --list                   # List providers
node call-llm.js --help                   # Show help

# Maintenance (2)

node configure-apis.js --test             # Test all providers
node configure-apis.js --usage            # Show usage stats
```

**Next Steps:** Run `node configure-apis.js` to begin setup!
